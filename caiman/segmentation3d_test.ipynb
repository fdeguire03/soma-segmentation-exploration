{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2e01a32-7148-46e6-8630-4eb2d3a34649",
   "metadata": {},
   "source": [
    "Following the tutorial for CAIMAN 3D segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda3cfd-399a-4d32-80f2-31d0ed955a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from caiman import load_memmap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import get_ipython\n",
    "import logging\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tifffile.tifffile import imwrite\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.utils.visualization import nb_view_patches3d\n",
    "import caiman.source_extraction.cnmf as cnmf\n",
    "from caiman.paths import caiman_datadir\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "        get_ipython().run_line_magic('autoreload', '2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import bokeh.plotting as bpl\n",
    "bpl.output_notebook()\n",
    "\n",
    "logging.basicConfig(format=\n",
    "                    \"%(relativeCreated)12d [%(filename)s%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\n",
    "                    level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afbdaf6-1c2b-470d-b761-85bb38241609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data (remember to subtract the minimum value so that the scan is positive (necessary for CNMF)\n",
    "\n",
    "filename = 'onefield_miniscan.npy'\n",
    "scan = np.load(filename)\n",
    "scan -= np.min(scan)\n",
    "print(scan.shape, np.min(scan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ea2dd-d7d7-48d8-9c3d-2814c14fc072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scan into the shape expected by the segmentation method\n",
    "\n",
    "Y = np.swapaxes(scan, 0, 3)\n",
    "Y2 = np.moveaxis(scan, 2, 0)\n",
    "dims = Y.shape[1:]\n",
    "print(Y2.shape)\n",
    "Cn = cm.local_correlations(Y, swap_dim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11056c3a-e521-4d68-9d4e-9a7b9f5f93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, d2, d3 = dims\n",
    "x, y = (int(1.2 * (d1 + d3)), int(1.2 * (d2 + d3)))\n",
    "scale = 6/x\n",
    "fig = plt.figure(figsize=(scale*x, scale*y))\n",
    "axz = fig.add_axes([1-d1/x, 1-d2/y, d1/x, d2/y])\n",
    "plt.imshow(Cn.max(2).T, cmap='gray')\n",
    "plt.title('Max.proj. z')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "axy = fig.add_axes([0, 1-d2/y, d3/x, d2/y])\n",
    "plt.imshow(Cn.max(0), cmap='gray')\n",
    "plt.title('Max.proj. x')\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('y')\n",
    "axx = fig.add_axes([1-d1/x, 0, d1/x, d3/y])\n",
    "plt.imshow(Cn.max(1).T, cmap='gray')\n",
    "plt.title('Max.proj. y')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('z');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f884928d-1ec8-44b7-9ada-5c8313baa718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='multiprocessing', n_processes=8, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe64e8-8ae4-4430-9ffd-c32b5e9a8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a tiff file, which the tutorial wants you to do\n",
    "\n",
    "fname = 'caiman-tutorial/scanMovieOneFieldAllFrames.tif'\n",
    "imwrite(fname, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd8f06b-5a33-41c1-ac96-529ac2aa1d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion correction parameters\n",
    "opts_dict = {'fnames': fname,\n",
    "             'strides': (24, 24, 6),    # start a new patch for pw-rigid motion correction every x pixels\n",
    "            'overlaps': (12, 12, 2),   # overlap between patches (size of patch strides+overlaps)\n",
    "            'max_shifts': (4, 4, 2),   # maximum allowed rigid shifts (in pixels)\n",
    "            'max_deviation_rigid': 5,  # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "            'pw_rigid': False,         # flag for performing non-rigid motion correction\n",
    "            'is3D': True}\n",
    "\n",
    "opts = cnmf.params.CNMFParams(params_dict=opts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c827e6-177e-4a4a-a171-592f3f2e6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we create a motion correction object with the parameters specified\n",
    "mc = cm.motion_correction.MotionCorrect(fname, dview=dview, **opts.get_group('motion'))\n",
    "# note that the file is not loaded in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47279231-6f95-40e4-a52d-d650e6e96b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% Run motion correction using NoRMCorre\n",
    "mc.motion_correct(save_movie=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ddc7b2-e97c-4e27-85fc-410852497852",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(1,1,1)\n",
    "for k in (0,1,2):\n",
    "    plt.plot(np.array(mc.shifts_rig)[:,k], label=('x','y','z')[k])\n",
    "plt.legend()\n",
    "plt.title('inferred shifts')\n",
    "plt.xlabel('frames')\n",
    "plt.ylabel('pixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522712e7-533a-4d42-a16b-be411c87b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% MEMORY MAPPING\n",
    "# memory map the file in order 'C'\n",
    "fname_new = cm.save_memmap(mc.mmap_file, base_name='memmap_', order='C',\n",
    "                           border_to_0=0, dview=dview) # exclude borders\n",
    "\n",
    "# now load the file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F') \n",
    "    #load frames in python format (T x X x Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71169386-7e53-41e7-9d4c-ba46ad3a1bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% restart cluster to clean up memory\n",
    "cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='multiprocessing', n_processes=8, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4134ec22-9995-4772-814f-1e538b45829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "patch_size = np.array([20,20,10])\n",
    "num_background_components = 1\n",
    "merge_threshold = 0.7\n",
    "fps = 8.3091\n",
    "proportion_patch_overlap = 0.2\n",
    "num_components_per_patch = 8\n",
    "init_method = 'greedy_roi'\n",
    "soma_diameter = np.array([3.2,3.2,3])\n",
    "num_pixels_per_process = 1000\n",
    "\n",
    "half_patch_size = np.int32(np.round(patch_size/2))\n",
    "patch_overlap = np.int32(np.round(patch_size*proportion_patch_overlap))\n",
    "patch_overlap[-1] = 2\n",
    "\n",
    "rf = half_patch_size  # half-size of the patches in pixels. rf=25, patches are 50x50\n",
    "stride = patch_overlap  # amount of overlap between the patches in pixels\n",
    "K = num_components_per_patch  # number of neurons expected per patch\n",
    "gSig = soma_diameter/2  # expected half size of neurons\n",
    "merge_thresh = merge_threshold  # merging threshold, max correlation allowed\n",
    "p = 2  # order of the autoregressive system\n",
    "print('set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082864d8-30c1-4ea0-bd10-d42264c3a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnm = cnmf.CNMF(n_processes, \n",
    "                k=K, \n",
    "                gSig=gSig, \n",
    "                merge_thresh=merge_thresh, \n",
    "                p=p, \n",
    "                dview=dview,\n",
    "                rf=rf, \n",
    "                stride=stride, \n",
    "                only_init_patch=True)\n",
    "cnm.params.set('spatial', {'se': np.ones((3,3,1), dtype=np.uint8)})\n",
    "cnm = cnm.fit(images)\n",
    "print(('Number of components:' + str(cnm.estimates.A.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef0af77-e07d-45af-a046-e989539a998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in two ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "\n",
    "fr = 10 # approx final rate  (after eventual downsampling )\n",
    "decay_time = 1.  # length of typical transient in seconds \n",
    "use_cnn = False  # CNN classifier is designed for 2d (real) data\n",
    "min_SNR = 3      # accept components with that peak-SNR or higher\n",
    "rval_thr = 0.6   # accept components with space correlation threshold or higher\n",
    "cnm.params.change_params(params_dict={'fr': fr,\n",
    "                                      'decay_time': decay_time,\n",
    "                                      'min_SNR': min_SNR,\n",
    "                                      'rval_thr': rval_thr,\n",
    "                                      'use_cnn': use_cnn})\n",
    "\n",
    "cnm.estimates.evaluate_components(images, cnm.params, dview=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e758743a-6400-44fd-84f6-27061a8caf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(('Keeping ' + str(len(cnm.estimates.idx_components)) +\n",
    "       ' and discarding  ' + str(len(cnm.estimates.idx_components_bad))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fe951-c640-4df5-abed-6ce236120658",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnm.params.set('temporal', {'p': p})\n",
    "cnm2 = cnm.refit(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12afaae-e07c-4d50-b3fc-edef23ab4d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.nb_view_components_3d(image_type='corr', \n",
    "                                     dims=dims, \n",
    "                                     Yr=Yr, \n",
    "                                     denoised_color='red', \n",
    "                                     max_projection=True,\n",
    "                                     axis=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fff291-c476-46e6-8ce2-fe5eb243050c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnm2.estimates.nb_view_components_3d(image_type='mean', dims=dims, axis=2);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edda2f5-b0f9-4719-9990-4f024716814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.A[:,59].toarray().reshape((240,240,10)).sum(axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0782d4-4938-4b59-b529-453141866191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% MEMORY MAPPING\n",
    "# memory map the file in order 'C'\n",
    "fname_2d = r'data/caiman/caiman_d1_240_d2_240_d3_1_order_C_frames_2500_.mmap'\n",
    "\n",
    "# now load the file\n",
    "Yr2d, dims2d, T2d = cm.load_memmap(fname_2d)\n",
    "images = np.reshape(Yr2d.T, [T2d] + list(dims2d), order='F') \n",
    "images -= np.min(images)\n",
    "    #load frames in python format (T x X x Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19594c46-8cba-4bd6-a04d-9af760c7c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% restart cluster to clean up memory\n",
    "cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='multiprocessing', n_processes=8, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c5858b-737b-40c7-ab13-d1b16123a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "patch_size = np.array([20,20])\n",
    "num_background_components = 1\n",
    "merge_threshold = 0.7\n",
    "fps = 8.3091\n",
    "proportion_patch_overlap = 0.2\n",
    "num_components_per_patch = 8\n",
    "init_method = 'greedy_roi'\n",
    "soma_diameter = np.array([3.2,3.2])\n",
    "num_pixels_per_process = 1000\n",
    "\n",
    "half_patch_size = np.int32(np.round(patch_size/2))\n",
    "patch_overlap = np.int32(np.round(patch_size*proportion_patch_overlap))\n",
    "patch_overlap[-1] = 2\n",
    "\n",
    "rf = half_patch_size  # half-size of the patches in pixels. rf=25, patches are 50x50\n",
    "stride = patch_overlap  # amount of overlap between the patches in pixels\n",
    "K = num_components_per_patch  # number of neurons expected per patch\n",
    "gSig = soma_diameter/2  # expected half size of neurons\n",
    "merge_thresh = merge_threshold  # merging threshold, max correlation allowed\n",
    "p = 2  # order of the autoregressive system\n",
    "print('set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6178735e-4978-4a82-9a23-9212c51a9ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnm2d = cnmf.CNMF(n_processes, \n",
    "                k=K, \n",
    "                gSig=gSig, \n",
    "                merge_thresh=merge_thresh, \n",
    "                p=p, \n",
    "                dview=dview,\n",
    "                rf=rf, \n",
    "                stride=stride, \n",
    "                only_init_patch=True)\n",
    "cnm2d = cnm2d.fit(images)\n",
    "print(('Number of components:' + str(cnm2d.estimates.A.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e3058c-a191-4eca-9c3d-b6f99106f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in two ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "\n",
    "fr = 10 # approx final rate  (after eventual downsampling )\n",
    "decay_time = 1.  # length of typical transient in seconds \n",
    "use_cnn = False  # CNN classifier is designed for 2d (real) data\n",
    "min_SNR = 3      # accept components with that peak-SNR or higher\n",
    "rval_thr = 0.6   # accept components with space correlation threshold or higher\n",
    "cnm2d.params.change_params(params_dict={'fr': fr,\n",
    "                                      'decay_time': decay_time,\n",
    "                                      'min_SNR': min_SNR,\n",
    "                                      'rval_thr': rval_thr,\n",
    "                                      'use_cnn': use_cnn})\n",
    "\n",
    "cnm2d.estimates.evaluate_components(images, cnm2d.params, dview=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa55700e-503a-47df-ae22-a0b9a63b6166",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(('Keeping ' + str(len(cnm2d.estimates.idx_components)) +\n",
    "       ' and discarding  ' + str(len(cnm2d.estimates.idx_components_bad))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0eab4f-6519-4b79-9ea3-e420d6e4bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnm2d.params.set('temporal', {'p': p})\n",
    "cnm2d = cnm2d.refit(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae38819-9d52-47cd-bcff-97d6210ce886",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2d.estimates.dims = dims2d\n",
    "\n",
    "\n",
    "\n",
    "cnm2d.estimates.nb_view_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a782199-9829-449b-aff0-ee1377565194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP CLUSTER\n",
    "cm.stop_server(dview=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c6fc9-efd8-4e64-8bf9-c72499a9fcde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d783af20-a86c-4f27-b1a5-801b3d3f4d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ce9e8-0f3b-42d5-83be-806ac286aa08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b10906-63d6-460b-bc85-1a9a4201a20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb33df-f304-4d10-9ced-c73f27e1a200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d72a4-5c45-445f-be30-41d2193f2730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52586711-e3be-4b46-b047-f63ad5e3bbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
